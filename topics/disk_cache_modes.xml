<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<topic xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="cha-cachemodes">
 <title>Disk Cache Modes</title>
 <para>
  Caching of disk devices affects the performance of guest machines. There are
  no simple rules to determine what combination of cache mode, disk image
  format, image placement, or storage sub-system is best. You need to plan each
  guest's configuration carefully and experiment with configurations to reach
  the optimal performance.
 </para>
 <section xml:id="cache-modes-description">
  <title>Description of Cache Modes</title>
  <para>
   If you do not specify a cache mode, <literal>writeback</literal> is used by
   default. Each guest disk can use a one of the following cache modes:
  </para>
  <variablelist>
   <varlistentry xml:id="cache-writeback">
    <term>writeback</term>
    <listitem>
     <para>
      <literal>writeback</literal> uses the host page cache. Writes are
      reported to the guest as completed when they are placed in the host page
      cache. The normal page cache management will handle commitment to the
      storage device. The guest's virtual storage adapter is informed of the
      writeback cache and therefore expected to send flush commands as needed
      to manage data integrity.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry xml:id="cache-writethrough">
    <term>writethrough</term>
    <listitem>
     <para>
      Writes are reported as completed only when the data has been committed to
      the storage device. The guest's virtual storage adapter is informed that
      there is no writeback cache, so the guest would not need to send down
      flush commands to manage data integrity.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry xml:id="cache-none">
    <term>none</term>
    <listitem>
     <para>
      The host page cache is bypassed and reads and writes happen directly
      between the hypervisor user space buffers and the storage device. Because
      the actual storage device may report a write as completed when placed in
      its write queue only, the guest's virtual storage adapter is informed
      that there is a <literal>writeback</literal> cache. This mode is
      equivalent to direct access to your host's disk.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry xml:id="cache-unsafe">
    <term>unsafe</term>
    <listitem>
     <para>
      Similar to the <literal>writeback</literal> mode except that all flush
      commands from the guests are ignored. Using this mode implies that the
      user prefers performance gain with the risk of data loss in case of a
      host failure. Useful, for example, during guest installation, but not for
      production workloads.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry xml:id="cache-directsync">
    <term>directsync</term>
    <listitem>
     <para>
      Writes are reported as completed only when the data has been committed to
      the storage device and the host page cache is bypassed. Similar to the
      <literal>writethrough</literal> mode, it is useful to guests that do not
      send flushes when needed. This was the last cache mode added, completing
      the possible combinations of caching and direct access strategies.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </section>
 <section xml:id="cache-modes-data-integrity">
  <title>Cache Modes and Data Integrity</title>
  <variablelist>
   <varlistentry>
    <term>writethrough, none, directsync</term>
    <listitem>
     <para>
      These are the safest modes and considered equally safe if the guest
      operating system uses flushes as needed. If you have a suspect guest, use
      <emphasis>writethough</emphasis> or <emphasis>directsync</emphasis>. Note
      that some file systems are not compatible with <literal>none</literal> or
      <literal>directsync</literal>
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>writeback</term>
    <listitem>
     <para>
      This mode informs the guest of the presence of a write cache, and relies
      on the guest to send flush commands as needed to maintain data integrity
      within its disk image. This mode exposes the guest to data loss in the
      unlikely case of a host failure, because there is a window of time
      between the time a write is reported as completed, and that write being
      committed to the storage device.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>unsafe</term>
    <listitem>
     <para>
      This mode is similar to <emphasis>writeback</emphasis> caching except for
      the following: the guest flush commands are ignored, nullifying the data
      integrity control of these flush commands, and resulting in a higher risk
      of data loss because of host failure. The name <quote>unsafe</quote>
      should serve as a warning that there is a much higher potential for data
      loss in case of a host failure than with the other modes. As the guest
      terminates, the cached data is flushed at that time.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </section>
 <section xml:id="cache-modes-performance">
  <title>Cache Modes and Performance</title>
  <para>
   The choice to make full use of the page cache, or to write through it, or to
   bypass it altogether can have dramatic performance implications. Other
   factors that influence disk performance include the capabilities of the
   actual storage system, what disk image format is used, the potential size of
   the page cache and the IO scheduler used. Additionally, not flushing the
   write cache increases performance, but with the risk of losing data. As a
   general rule, high-end systems typically perform best with the cache mode
   <literal>none</literal>, because of the reduced data copying that occurs.
   The potential benefit of having multiple guests share the common host page
   cache, the ratio of reads to writes, and the use of AIO mode
   <literal>native</literal> (see below) should also be considered.
  </para>
 </section>
 <section xml:id="cache-modes-live-migration">
  <title>Cache Modes and Live Migration</title>
  <para>
   The caching of storage data and metadata restricts the configurations that
   support live migration. Currently, only <literal>raw</literal> and
   <literal>qcow2</literal> image formats can be used for live migration. If a
   clustered file system is used, all cache modes support live migration.
   Otherwise the only cache mode that supports live migration on read/write
   shared storage is <literal>none</literal>.
  </para>
  <para>
   The &libvirt; management layer includes checks for migration compatibility
   based on several factors. If the guest storage is hosted on a clustered file
   system, is read-only or is marked shareable, then the cache mode is ignored
   when determining if migration can be allowed. Otherwise &libvirt; will not
   allow migration unless the cache mode is set to <literal>none</literal>.
   However, this restriction can be overridden with the <quote>unsafe</quote>
   option to the migration APIs, which is also supported by
   <command>virsh</command>. For example
  </para>
<screen>&prompt.user;virsh migrate --live --unsafe</screen>
  <tip>
   <para>
    The cache mode <literal>none</literal> is required for the AIO mode setting
    <literal>native</literal>. If another cache mode is used, then the AIO mode
    will silently be switched back to the default <literal>threads</literal>.
   </para>
  </tip>
 </section>
</topic>
