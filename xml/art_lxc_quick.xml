<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE chapter PUBLIC "-//Novell//DTD NovDoc XML V1.0//EN" "novdocx.dtd"
[
  <!ENTITY % NOVDOC.DEACTIVATE.IDREF "INCLUDE">
  <!ENTITY % entities SYSTEM "entity-decl.ent">
  %entities;
]>
<!--taroth 2014-03-19: fcrozat: lxc as in SLE11 has been removed from SLE12, it will be handled by
libvirt-->
<!-- fs 2011-07-18:

FATE #312024

Related Features:
 * Promote lxc to L3 support for SLES 11 SP2 for limited szenarios, full support
   in SLES 11 SP3 (latest) (312040)
 * YaST module for lxc, soft partitioning / containers implementation (312041)
   Rejected for SLES11 SP2
 * Clustering and monitoring capabilities for Linux Containers / LXC (312043)
   Rejected for SLES11 SP2
 * Integrate rwtab / read-only root filesystems with Linux Containers / lxc
   (312044)
   Rejected for SLES11 SP2
 * libvirt

Resources:
~~~~~~~~~~
 - https://wiki.archlinux.org/index.php/Linux_Containers
 - http://lxc.teegra.net/
 - http://www.linuxtag.de/2011/de/program/business-und-behoerdenkongress/vortragsdetails-talkid107.html
 - http://en.opensuse.org/LXC
 - http://www.linuxtag.org/2011/fileadmin/www.linuxtag.org/slides/Christoph%20Mitasch%20-%20Lightweight%20virtualization%3A%20LXC%20vs.%20OpenVZ.pdf

 - http://www.suse.com/documentation/sles11/book_sle_tuning/data/cha_tuning_cgroups.html
 - https://www.ibm.com/developerworks/linux/library/l-lxc-containers/
 - http://berrange.com/posts/2011/09/27/getting-started-with-lxc-using-libvirt/
 - http://blog.flameeyes.eu/2010/09/04/linux-containers-and-networking

People
~~~~~~
Frederic Crozat (Developer)
Matthias Eckermann (PM)
Darix
Berthold
(Adrian)

-->
<!-- fs 2011-09-28:
     Is the bridge needed in any case or is it possible to use e.g. eth1
     exclusively for a container?
     If so, this should be mentioned in the host setup part and  in the
     config file generation part (lxc.network.link)

-->
<chapter id="cha.lxc">
 <title>&lxcquick;</title>
 <abstract>
  <para>
   &lxc; is a lightweight <quote>virtualization</quote> method to run
   multiple virtual units (containers, akin to <quote>chroot</quote>)
   simultaneously on a single control host. Containers are isolated with
   Kernel Control Groups (cgroups) and Kernel Namespaces.
  </para>

  <para>
   &lxc; provides an operating system-level virtualization where the
   <emphasis>Kernel</emphasis> controls the isolated containers. With other
   full virtualization solutions like &xen; or &kvm; the
   <emphasis>processor</emphasis> simulates a complete hardware environment
   and controls its virtual machines.
  </para>
 </abstract>
<!-- ========================================================= -->
 <sect1 id="sec.lxc.terminology">
  <title>Terminology</title>

  <variablelist>
   <varlistentry>
    <term>chroot</term>
    <listitem>
     <para>
      A <emphasis>change root</emphasis> (chroot, or change root jail) is a
      section in the file system which is isolated from the rest of the file
      system. For this purpose, the <command>chroot</command> or
      <command>pivot_root</command> command is used to change the root of
      the file system. A program which is executed in such a <quote>chroot
      jail</quote> cannot access files outside the designated directory
      tree.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>cgroups</term>
    <listitem>
     <para>
      Kernel Control Groups (commonly referred to as just
      <quote>cgroups</quote>) are a Kernel feature that allows aggregating
      or partitioning tasks (processes) and all their children into
      hierarchical organized groups to isolate resources.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Container</term>
    <listitem>
     <para>
      A <quote>virtual machine</quote> on the host server that can run any
      Linux system, for example &opensuse;, &sled;, or &sls;.
     </para>
    </listitem>
   </varlistentry>
<!-- Do we still need this entry? -->
   <varlistentry>
    <term>Container Name</term>
    <listitem>
     <para>
      A name that refers to a container. The name is used by the
      <literal>lxc</literal> commands.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Kernel Namespaces</term>
    <listitem>
     <para>
      A Kernel feature to isolate some resources like network, users, and
      others for a group of processes.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>&lxc; Host Server</term>
    <listitem>
     <para>
      The system that contains the &lxc; system and provides the containers
      and management control capabilities through cgroups.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
<!-- ========================================================= -->
 <sect1 id="sec.lxc.overview">
  <title>Overview</title>

  <para>
   Conceptually, &lxc; can be seen as an improved
   <emphasis>chroot</emphasis> technique. The difference is that a chroot
   environment separates only the file system, whereas &lxc; goes further
   and provides resource management and control via cgroups.
  </para>

  <itemizedlist>
   <title>Benefits of &lxc;</title>
   <listitem>
    <para>
     Isolating applications and operating systems through containers.
    </para>
   </listitem>
   <listitem>
    <para>
     Providing nearly native performance as &lxc; manages allocation of
     resources in real-time.
    </para>
   </listitem>
   <listitem>
    <para>
     Controlling network interfaces and applying resources inside containers
     through cgroups.
    </para>
   </listitem>
  </itemizedlist>

  <itemizedlist>
   <title>Limitations of &lxc;</title>
   <listitem>
    <para>
     All &lxc; containers are running inside the host system's Kernel and
     not with a different Kernel.
    </para>
   </listitem>
   <listitem>
    <para>
     Only allows Linux <quote>guest</quote> operating systems.
    </para>
   </listitem>
   <listitem>
    <para>
     Security depends on the host system. &lxc; is not secure. If you need a
     secure system, you can confine it using an AppArmor profile.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
<!-- ========================================================= -->
 <sect1 id="sec.lxc.setup.host">
  <title>Setting up an &lxc; Host</title>

  <para>
   The &lxc; host provides the cgroups and controls all containers. The
   &lxc; containers are handled through &libvirt;.
  </para>

  <procedure id="pro.lxc.setup">
   <title>Preparing an &lxc; Host</title>
   <step>
    <para>
     Install the following packages:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       libvirt-daemon-lxc
      </para>
     </listitem>
     <listitem>
      <para>
       pm-utils
      </para>
     </listitem>
     <listitem os="osuse">
      <para>
       kernel-default
      </para>
     </listitem>
    </itemizedlist>
    <para os="osuse">
     In case you have a desktop Kernel installed, remove it with the command
     <command >zypper</command> <command>rm</command>
     <option>kernel-desktop</option>. Install the default Kernel and reboot
     your machine.
    </para>
   </step>
<!-- TODO Add a step to start libvirtd.service or describe install using
        Yast 'Install Hypervisor and Tools' when it will support lxc -->
  </procedure>

  <para>
   &lxc; starts the cgroup service automatically. The &lxc; host is now
   prepared for setting up containers.
  </para>
 </sect1>

<!-- ========================================================= -->
<!-- TODO fill this section with NETNS -->
 <sect1>
  <title>Setting up the system</title>
  <para>
   FIXME: System lacks NETNS support, need to be configured first.
  </para>
 </sect1>

<!-- ========================================================= -->
<!-- TODO Completely setting up lxc containers using YaST/virt-manager
     is not yet possible. -->
 <sect1 id="sec.lxc.setup.container">
  <title>Setting up &lxc; distribution containers</title>

  <para>
   A container is a <quote>virtual machine</quote> that can be started,
   stopped, frozen, or cloned (to name but a few tasks). To set up an &lxc;
   container, you first need to create a root file system containing the
   guest distribution:
  </para>

  <procedure id="pro.lxc.create-rootfs">
   <title>Creating a root file system</title>
   <para>
    There is currently no GUI to create a root file system. You will thus
    need to open a terminal and use zypper to populate the new root file
    system. In the following steps, the new root file system will be created
    in <replaceable>/path/to/rootfs</replaceable>.
   </para>
   <step>
    <para>
     Add the repository for the &sls; or &opensuse; DVD or its ISO image.
     Update repositories should also be added using a similar command.
    </para>
<screen>zypper --root <replaceable>/path/to/rootfs</replaceable> ar cd:///?devices=/dev/dvd dvd</screen>
   </step>
   <step>
    <para>
     Install the packages needed in the root file system. Of course, more
     packages can be installed, depending on the needs for the container.
    </para>
<screen>zypper --root <replaceable>/path/to/rootfs</replaceable> in --no-recommends patterns-sles-Minimal</screen>
   </step>
   <step>
    <para>
     Change the root path to the root file system with the
     <command>chroot</command> command:
    </para>
<screen>chroot <replaceable>/path/to/rootfs</replaceable></screen>
   </step>
   <step>
    <para>
     Change the password for user &rootuser; with <command>passwd
     root</command>.
    </para>
   </step>
   <step>
    <para>
     Create an <systemitem class="username">operator</systemitem> user
     without &rootuser; privileges:
    </para>
<screen>useradd -m operator</screen>
   </step>
   <step>
    <para>
     Change the operator's password:
    </para>
<screen>passwd operator</screen>
   </step>
   <step>
    <para>
     Leave the chroot environment with <command>exit</command>.
    </para>
   </step>
  </procedure>

  <procedure id="pro.lxc.define-gui">
   <title>Defining the Container using &yast;</title>
   <step>
    <para>
     Open &yast; and go to the Virtual Machine Manager module.
    </para>
   </step>
   <step>
    <para>
     Add the LXC connection by clicking on <guimenu>File</guimenu>
     <guimenu>Add Connection</guimenu> menu. Select <guimenu>LXC (Linux
     Containers)</guimenu> as hypervisor and click the
     <guimenu>Connect</guimenu> button.
    </para>
   </step>
   <step>
    <para>
     Select the <guimenu>localhost (LXC)</guimenu> connection and click on
     <guimenu>File</guimenu> <guimenu>New Virtual Machine</guimenu> menu.
    </para>
    <para>
     Select the <guimenu>Operating system container</guimenu> option and
     click on the <guimenu>Forward</guimenu> button.
    </para>
   </step>
   <step>
    <para>
     Type the path to the root filesystem from
     <xref linkend="pro.lxc.create-rootfs"/> and click the
     <guimenu>Forward</guimenu> button.
    </para>
   </step>
   <step>
    <para>
     Choose the maximum amount of memory and CPUs to allocate to the
     container. Then click on the <guimenu>Forward</guimenu> button.
    </para>
   </step>
   <step>
    <para>
     Type in a name for the container. This name will be used for all
     <command>virsh</command> commands on the container.
    </para>
    <para>
     Click on the <guimenu>Advanced options</guimenu>.
     Select the network to connect the container to and click the
     <guimenu>Finish</guimenu> button: the container will then be created
     and started.
    </para>
   </step>
  </procedure>

<!--
       FIXME: Is this  still needed since all handling happens with libvirt?
              The only case we may need to add something here is about lxc-enter-namespace.
  <procedure id="pro.lxc.operating">
   <title>Starting, Accessing, and Stopping Your Container Manually</title>
   <step>
    <para>
     Start the container:
    </para>
<screen>lxc-start -d -n <replaceable>CONTAINER_NAME</replaceable></screen>
   </step>
   <step>
    <para>
     Connect to the container and log in:
    </para>
<screen>lxc-console -n <replaceable>CONTAINER_NAME</replaceable></screen>
   </step>
   <step>
    <para>
     Stop and remove your container <emphasis>always</emphasis> with the two
     steps:
    </para>
<screen>lxc-stop -n <replaceable>CONTAINER_NAME</replaceable>
lxc-destroy -n <replaceable>CONTAINER_NAME</replaceable></screen>
   </step>
  </procedure>
-->
 </sect1>
<!-- ========================================================= -->
<!-- FIXME Do we need this here? this is now generic libvirt doc -->
 <sect1 id="sec.lxc.startup">
  <title>Starting Containers at Boot Time</title>

  <para>
   &lxc; containers can be started at boot time. However, you need to follow
   certain conventions. Every container has a subdirectory with its name in
   <filename>/etc/lxc/</filename>, for example,
   <filename>/etc/lxc/my-sles</filename>. This directory needs to be created
   once. There you place your configuration file (named
   <filename>config</filename>).
  </para>

  <para>
   To set up the automatic start of &lxc; containers, proceed as follows:
  </para>

  <procedure>
   <step>
    <para>
     Activate the cgroup service with <command>sudo systemctl enable
     cgroup.service</command>. This has to be done only once to enable this
     service at boot time. The command will populate the
     <filename>/sys/fs/cgroup</filename> directory.
    </para>
   </step>
   <step>
    <para>
     Create a directory
     <filename>/etc/lxc/<replaceable>CONTAINER</replaceable></filename>.
    </para>
   </step>
   <step>
    <para>
     Copy your configuration file to
     <filename>/etc/lxc/<replaceable>CONTAINER</replaceable>/config</filename>.
    </para>
   </step>
   <step>
    <para>
     Run <command>sudo systemctl start cgroup.service</command> to set up
     cgroups properly.
    </para>
   </step>
   <step>
    <para>
     Run <command>sudo systemctl start lxc.service</command> to start your
     containers.
    </para>
   </step>
   <step>
    <para>
     Wait a few seconds and run
     <remark>taroth 2014-03-07: FIXME - SYSTEMD:
      @file-maintainer: I'm not sure "list" can be passed to systemctl - either
      file bug to maintain this as legacy stuff (see
      https://bugzilla.novell.com/show_bug.cgi?id=861124) or check with subject
      matter expert what to do here</remark>
     <command>/etc/init.d/lxc <option>list</option></command> to print the
     state of all your containers.
    </para>
   </step>
  </procedure>

  <para>
   After this procedure, your &lxc; containers are correctly configured. To
   start it automatically next time you boot your computer, use
   <command>systemctl enable lxc.service</command>.
  </para>
 </sect1>
<!-- ========================================================= -->
 <sect1 id="sec.lxc.moreinfo">
  <title>For More Information</title>

  <variablelist>
   <varlistentry>
    <term>Kernel Control Groups (cgroups)</term>
    <listitem>
     <para>
      <ulink
            url="http://www.suse.com/documentation/sles11/book_sle_tuning/data/cha_tuning_cgroups.html"
          />
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>&lxc; Container Driver</term>
    <listitem>
     <para>
      <ulink url="http://libvirt.org/drvlxc.html"/>
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
</chapter>
