<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
  %entities;
]>

<chapter xmlns="http://docbook.org/ns/docbook"
         xmlns:xi="http://www.w3.org/2001/XInclude"
         xmlns:xlink="http://www.w3.org/1999/xlink"
         version="5.0" xml:id="cha-tuning-cgroups">

 <title>Kernel Control Groups</title>
 <info>
  <abstract>
   <para>
    Kernel Control Groups (<quote>cgroups</quote>) are a kernel feature
    that allows assigning and limiting hardware and system resources for processes.
    Processes can also be organized in a hierarchical tree structure.
   </para>
  </abstract>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:bugtracker>
   </dm:bugtracker>
  </dm:docmanager>
 </info>

 <sect1 xml:id="sec-tuning-cgroups-overview">
  <title>Overview</title>
  <para>
   Every process is assigned exactly one administrative cgroup. cgroups are ordered
   in a hierarchical tree structure. You can set resource limitations, such as
   CPU, memory, disk I/O, or network bandwidth usage,for single processes or for 
   whole branches of the hierarchy tree.
  </para>
  <para>
   On &productname;, &systemd; uses cgroups to organize all
   processes in groups, which &systemd; calls slices. &systemd; also
   provides an interface for setting cgroup properties.
  </para>
  <para>
   The command <command>systemd-cgls</command> displays the hierarchy
   tree.
  </para>
  <para>
   This chapter is an overview. For more details, refer to the listed
   references.
  </para>
 </sect1>

 <sect1 xml:id="sec-tuning-cgroups-usage">
  <title>Setting Resource Limits</title>
  <note>
    <title>Implicit Resource Consumption</title>
    <para>
      Be aware that resource consumption implicitly depends on the environment
      where your workload executes (e.g. size of data structures in libraries/kernel,
      forking behavior of utilities, computational efficiency),
      hence it is recommended to (re)calibrate your limits should the environment change.
    </para>
  </note>
  <para>
   Limitations to <literal>cgroups</literal> can be set with the
   <command>systemctl set-property</command> command. The syntax is:
  </para>
  <screen>&prompt.root;<command>systemctl set-property [--runtime] <replaceable>NAME</replaceable> <replaceable>PROPERTY1</replaceable>=<replaceable>VALUE</replaceable> [<replaceable>PROPERTY2</replaceable>=<replaceable>VALUE</replaceable>]</command></screen>
  <para>
   Optionally, use the <option>--runtime</option> option. With this
   option, set limits do not persist after the next reboot.
  </para>
  <para>
   Replace <replaceable>NAME</replaceable> with a &systemd; service
   slice, scope, socket, mount, or swap name. Replace properties with
   one or more of the following:
  </para>
  <variablelist>
   <varlistentry>
    <term><literal>CPUAccounting=</literal><option>[yes|no]</option></term>
    <listitem>
     <para>
      Turns on CPU usage accounting. This property takes
      <literal>yes</literal> and <literal>no</literal> as arguments.
     </para>
     <para>
      Example:
     </para>
     <screen>&prompt.root;<command>systemctl set-property user.slice CPUAccounting=yes</command></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>CPUQuota=</literal><replaceable>PERCENTAGE</replaceable></term>
    <listitem>
     <para>
      Assigns a CPU time to processes. The value is a percentage
      followed by a <literal>%</literal> as suffix. This implies
      <literal>CPUAccounting=yes</literal>.
     </para>
     <para>
      Example:
     </para>
     <screen>&prompt.root;<command>systemctl set-property user.slice CPUQuota=50%</command></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>MemoryAccounting=</literal><option>[yes|no]</option></term>
    <listitem>
     <para>
      Turns on memory usage accounting. This property takes
      <literal>yes</literal> and <literal>no</literal> as arguments.
     </para>
     <para>
      Example:
     </para>
     <screen>&prompt.root;<command>systemctl set-property user.slice MemoryAccounting=yes</command></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>MemoryLow=</literal><replaceable>BYTES</replaceable></term>
    <listitem>
     <para>
      Unused memory from processes below this limit will not be
      reclaimed for other use. Use suffixes K, M, G or T for
      <replaceable>BYTES</replaceable>. This implies
      <literal>MemoryAccounting=yes</literal>.
     </para>
     <para>
      Example:
     </para>
     <screen>&prompt.root;<command>systemctl set-property nginx.service MemoryLow=512M</command></screen>
     <note>
      <title>Unified Control Group Hierarchy</title>
      <para>
       This setting is available only if the unified control group hierarchy is
       used, and disables <option>MemoryLimit=</option>. To enable the unified
       control group hierarchy, append
       <option>systemd.unified_cgroup_hierarchy=1</option> as a kernel command
       line parameter to the &grub; boot loader. Refer to <xref
        linkend="cha-grub2"/> for more details about configuring &grub;.
      </para>
     </note>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>MemoryHigh=</literal><replaceable>BYTES</replaceable></term>
    <listitem>
     <para>
      If more memory above this limit is used, memory is aggressively
      taken away from the processes. Use suffixes K, M, G or T for
      <replaceable>BYTES</replaceable>. This implies
      <literal>MemoryAccounting=yes</literal>.
     </para>

     <para>
      Example:
     </para>
     <screen>&prompt.root;<command>systemctl set-property nginx.service MemoryHigh=2G</command></screen>
     <note>
      <title>Unified Control Group Hierarchy</title>
      <para>
       This setting is available only if the unified control group hierarchy is
       used, and disables <option>MemoryLimit=</option>. To enable the unified
       control group hierarchy, append
       <option>systemd.unified_cgroup_hierarchy=1</option> as a kernel command
       line parameter to the &grub; boot loader. Refer to <xref
        linkend="cha-grub2"/> for more details about configuring &grub;.
      </para>
     </note>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>MemoryMax=</literal><replaceable>BYTES</replaceable></term>
    <listitem>
     <para>
      Sets a maximum limit for used memory. Processes will be killed if
      they use more memory than allowed. Use suffixes K, M, G or T for
      <replaceable>BYTES</replaceable>. This implies
      <literal>MemoryAccounting=yes</literal>.
     </para>
     <para>
      Example:
     </para>
     <screen>&prompt.root;<command>systemctl set-property nginx.service MemoryMax=4G</command></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>DeviceAllow=</literal></term>
    <listitem>
     <para>
      Allows read (<literal>r</literal>), write (<literal>w</literal>)
      and mknod (<literal>m</literal>) access. The command takes a
      device node specifier and a list of <literal>r</literal>, <literal>w</literal> or
      <literal>m</literal>, separated by a white space.
     </para>
     <para>
      Example:
     </para>
     <screen>&prompt.root;<command>systemctl set-property system.slice DeviceAllow="/dev/sdb1 r"</command></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>DevicePolicy=</literal><option>[auto|closed|strict]</option></term>
    <listitem>
     <para>
      When set to <literal>strict</literal>, only access to devices
      that are listed in <literal>DeviceAllow</literal> is allowed.
      <literal>closed</literal> additionally allows access to standard
      pseudo devices including <filename>/dev/null</filename>,
      <filename>/dev/zero</filename>, <filename>/dev/full</filename>,
      <filename>/dev/random</filename>, and
      <filename>/dev/urandom</filename>.
      <literal>auto</literal> allows access to all devices if no
      specific rule is defined in <literal>DeviceAllow</literal>.
      <literal>auto</literal> is the default setting.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
  <para>
   For more details and a complete list of properties, see <command>man
   systemd.resource-control</command>.
  </para>
 </sect1>
 
 <sect1 xml:id="sec-tuning-cgroups-tasksmax">
  <title>Preventing Fork Bombs with TasksMax</title>
  <para>
      &systemd; 228 shipped with a <literal>DefaultTasksMax</literal> 
      limit of 512, which is set in 
      <filename>/etc/systemd/system.conf</filename>. This limits the
      number of tasks any &systemd; unit can create at one time to
      512. Previous versions had no default limit. The goal was to
      improve security by preventing runaway processes from creating
      excessive forks, or spawning enough threads to exhaust
      system resources.
  </para>
  <para>
      However, it soon became apparent that there is not a single
      default that applies to all use cases. 512 is not low enough
      to prevent a runaway process from crashing a system, especially 
      when other resources such as CPU and RAM are not restricted, 
      and not high enough for processes that create a lot of threads, 
      such as databases. In &systemd; 234 the default was changed to 15%, 
      which is 4915 tasks (15% of the kernel limit of 32768, 
      see <command>cat /proc/sys/kernel/pid_max</command>).
  </para>
  <para>
      &sle; ships with a custom configuration that overrides the upstream
      default. 
      <filename>/usr/lib/systemd/system.conf.d/20-suse-defaults.conf</filename>
      overrides the default limit with the following configuration:
  </para>
  <screen>
[Manager]
DefaultTasksMax=infinity
  </screen>
  <para>
      When you query the value with <command>systemctl</command> it looks like
      this:
  </para>
  <screen>&prompt.user;systemctl show --property DefaultTasksMax
DefaultTasksMax=18446744073709551615</screen>
  <para>
       This is the same as having no limit. It is not a requirement to change the 
       default, but setting some limits may help to prevent system crashes
       from runaway processes.
   </para>
   <para>
       Start by disabling the &sle; default by linking 
       <filename>20-suse-defaults.conf</filename> to 
       <filename>/dev/null</filename>, and putting the link in
       <filename>/etc/systemd/system.conf.d/</filename>. First create
       <filename>system.conf.d/</filename> if it does not exist, then 
       create the link:
   </para>
   <screen>&prompt.root;mkdir /etc/systemd/system.conf.d/
&prompt.root;ln -s /dev/null /etc/systemd/system.conf.d/20-suse-defaults.conf
   </screen>
   <para>
       Then change the global default by creating a new override
       file, <filename>/etc/systemd/system.conf.d/50-tasksmax.conf</filename>,
       and write the following lines to set new global limit of 256 tasks per 
       systemd unit:
   </para>
   <screen>
[Manager]
DefaultTasksMax=256
</screen>
   <para>
       Load the new setting, then verify that it changed:
   </para>
   <screen>&prompt.root;systemctl daemon-reload
&prompt.user;systemctl show --property DefaultTasksMax
DefaultTasksMax=256
   </screen>
   <para>
       You may adjust this value to suit your needs. Now you can set higher 
       limits on individual services as needed. This example is for MariaDB. 
       First check the current active value:
   </para>
   <screen>
&prompt.user;systemctl status mariadb.service
  ● mariadb.service - MariaDB database server
   Loaded: loaded (/usr/lib/systemd/system/mariadb.service; disabled; vendor pr>
   Active: active (running) since Tue 2020-05-26 14:15:03 PDT; 27min ago
     Docs: man:mysqld(8)
           https://mariadb.com/kb/en/library/systemd/
 Main PID: 11845 (mysqld)
   Status: "Taking your SQL requests now..."
    Tasks: 30 (limit: 256)
   CGroup: /system.slice/mariadb.service
           └─11845 /usr/sbin/mysqld --defaults-file=/etc/my.cnf --user=mysql
   </screen>
   <para>
       The Tasks line shows that MariaDB currently has 30 tasks running, and has
       an upper limit of 256. The following example demonstrates how to raise
       MariaDB's limit to 8096. Create a new override file,
       <filename>/etc/systemd/system.conf.d/30-mariadb.conf</filename>, 
       with the following lines, then reload:
   </para>
   <screen>
[Service]
TasksMax=8096
   </screen>
   <screen>&prompt.root;systemctl daemon-reload</screen>
   <para>
       The value does not have to be 8096, but can be whatever limit seems
       appropriate for your workloads, including <literal>infinity</literal>.
   </para>
   <para>
       You may also set custom values for user processes. The &sle; default
       is <literal>infinity</literal>, set in
       <filename>/usr/lib/systemd/system/user-.slice.d/20-suse-defaults.conf</filename>.
       Disable this default by linking it to <filename>/dev/null</filename>
       in <filename>/etc/systemd/user-.slice.d/</filename>:
   </para>
   <screen>&prompt.root;mkdir /etc/systemd/user-.slice.d/
&prompt.root;ln -s /dev/null /etc/systemd/user-.slice.d/20-suse-defaults.conf     
   </screen>
   <para>
       Create a new override file, 
       <filename>/etc/systemd/system/user-.slice.d/30-users-tasksmax.conf</filename>,
       with these lines:
   </para>
   <screen>
[Slice]
TasksMax=8096
   </screen>
   <para>
       If there is a <literal>UserTasksMax</literal> setting in
       <filename>/etc/systemd/logind.conf</filename>, comment it out.
       Then run <command>systemctl daemon-reload</command> to load the new value.
   </para>
   <para>
       To set a custom value for an individual user create an override file, for
       example 
       <filename>/etc/systemd/system/user-1000.slice.d/50-user-tasksmax.conf</filename>,
       with these lines:
   </para>
   <screen>
[Slice]
TasksMax=8096
   </screen>
   <para>
       Verify the new value:
   </para>
   <screen>&prompt.user;systemctl show --property TasksMax user-1000.slice
TasksMax=8096
   </screen>
   <para>
       The new value takes effect at the next user login.
   </para>
   <para>
       How do you know what values to use? This varies according to your workloads,
       system resources, and other resource configurations. When your user TasksMax 
       value is too low, you will see error messages like "Failed to fork (Resources
       temporarily unavailable)". Test this by setting the user TasksMax value
       to 128, then open some applications. To recover, close all apps 
       (except your terminal) and change the setting.
   </para>
   <para>
       System services will throw error messages like "Can't create thread to handle 
       new connection" and "Error: Function call 'fork' failed with error code 11, 
       'Resource temporarily unavailable'", depending on which service has run out
       of tasks.
   </para>
   <para>
       For more information on configuring system resources in systemd, see
       <literal>systemd.resource-control (5)</literal>.
   </para>
</sect1>

<sect1>
    <title>For More Information</title>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     Kernel documentation (package <systemitem>kernel-source</systemitem>):
     files in <filename>/usr/src/linux/Documentation/cgroups</filename>.
    </para>
   </listitem>
   <listitem>
    <para>
     <link xlink:href="http://lwn.net/Articles/604609/"/>&mdash;Brown,
     Neil: Control Groups Series (2014, 7 parts).
    </para>
   </listitem>
   <listitem>
    <para>
     <link xlink:href="http://lwn.net/Articles/243795/"/>&mdash;Corbet,
     Jonathan: Controlling memory use in containers (2007).
    </para>
   </listitem>
   <listitem>
    <para>
     <link xlink:href="http://lwn.net/Articles/236038/"/>&mdash;Corbet,
     Jonathan: Process containers (2007).
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
</chapter>
