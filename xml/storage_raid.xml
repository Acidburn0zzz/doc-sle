<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE chapter PUBLIC "-//Novell//DTD NovDoc XML V1.0//EN" "novdocx.dtd" [
  <!ENTITY % NOVDOC.DEACTIVATE.IDREF "INCLUDE">
  <!ENTITY % entities SYSTEM "entity-decl.ent">
  %entities;
]>
<chapter id="raidyast" lang="en">
  <title>Software RAID Configuration</title>
  <para>
   The purpose of RAID (redundant array of independent disks) is to combine
   several hard disk partitions into one large virtual hard disk to optimize
   performance, data security, or both. Most RAID controllers use the SCSI
   protocol because it can address a larger number of hard disks in a more
   effective way than the IDE protocol and is more suitable for parallel
   processing of commands. There are some RAID controllers that support IDE
   or SATA hard disks. Software RAID provides the advantages of RAID systems
   without the additional cost of hardware RAID controllers. However, this
   requires some CPU time and has memory requirements that make it
   unsuitable for real high performance computers.
  </para>
  <important>
   <para>
    Software RAID is not supported underneath clustered file systems such as
    OCFS2, because RAID does not support concurrent activation. If you want
    RAID for OCFS2, you need the RAID to be handled by the storage
    subsystem.
   </para>
  </important>
  <para>
   &sle; offers the option of combining several hard disks
   into one soft RAID system. RAID implies several strategies for combining
   several hard disks in a RAID system, each with different goals,
   advantages, and characteristics. These variations are commonly known as
   <emphasis>RAID levels</emphasis>.
  </para>
  <itemizedlist role="subtoc">
   <listitem>
    <para>
     <xref linkend="bi70wwi" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="sec.yast2.system.raid.yast" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="bgchysg" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="bgchysh" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
  </itemizedlist>
  <sect1 id="bi70wwi">
   <title>Understanding RAID Levels</title>

   <para>
    This section describes common RAID levels 0, 1, 2, 3, 4, 5, and nested
    RAID levels.
   </para>

   <itemizedlist role="subtoc">
    <listitem>
     <para>
      <xref linkend="bgchysa" xrefstyle="SectTitleOnPage"/>
     </para>
    </listitem>
    <listitem>
     <para>
      <xref linkend="bgchysb" xrefstyle="SectTitleOnPage"/>
     </para>
    </listitem>
    <listitem>
     <para>
      <xref linkend="bgchysc" xrefstyle="SectTitleOnPage"/>
     </para>
    </listitem>
    <listitem>
     <para>
      <xref linkend="bgchysd" xrefstyle="SectTitleOnPage"/>
     </para>
    </listitem>
    <listitem>
     <para>
      <xref linkend="bgchyse" xrefstyle="SectTitleOnPage"/>
     </para>
    </listitem>
    <listitem>
     <para>
      <xref linkend="bgchysf" xrefstyle="SectTitleOnPage"/>
     </para>
    </listitem>
   </itemizedlist>

   <sect2 id="bgchysa">
    <title>RAID&nbsp;0</title>
    <para>
     This level improves the performance of your data access by spreading
     out blocks of each file across multiple disk drives. Actually, this is
     not really a RAID, because it does not provide data backup, but the
     name <emphasis>RAID&nbsp;0</emphasis> for this type of system has
     become the norm. With RAID&nbsp;0, two or more hard disks are pooled
     together. The performance is very good, but the RAID system is
     destroyed and your data lost if even one hard disk fails.
    </para>
   </sect2>

   <sect2 id="bgchysb">
    <title>RAID&nbsp;1</title>
    <para>
     This level provides adequate security for your data, because the data
     is copied to another hard disk 1:1. This is known as <emphasis>hard
     disk mirroring</emphasis>. If a disk is destroyed, a copy of its
     contents is available on another mirrored disk. All disks except one
     could be damaged without endangering your data. However, if damage is
     not detected, damaged data might be mirrored to the correct disk and
     the data is corrupted that way. The writing performance suffers a
     little in the copying process compared to when using single disk access
     (10 to 20 percent slower), but read access is significantly faster in
     comparison to any one of the normal physical hard disks, because the
     data is duplicated so can be scanned in parallel. RAID 1 generally
     provides nearly twice the read transaction rate of single disks and
     almost the same write transaction rate as single disks.
    </para>
   </sect2>

   <sect2 id="bgchysc">
    <title>RAID&nbsp;2 and RAID&nbsp;3</title>
    <para>
     These are not typical RAID implementations. Level&nbsp;2 stripes data
     at the bit level rather than the block level. Level&nbsp;3 provides
     byte-level striping with a dedicated parity disk and cannot service
     simultaneous multiple requests. Both levels are rarely used.
    </para>
   </sect2>

   <sect2 id="bgchysd">
    <title>RAID&nbsp;4</title>
    <para>
     Level&nbsp;4 provides block-level striping like Level&nbsp;0 combined
     with a dedicated parity disk. If a data disk fails, the parity data is
     used to create a replacement disk. However, the parity disk might
     create a bottleneck for write access. Nevertheless, Level&nbsp;4 is
     sometimes used.
    </para>
   </sect2>

   <sect2 id="bgchyse">
    <title>RAID&nbsp;5</title>
    <para>
     RAID&nbsp;5 is an optimized compromise between Level&nbsp;0 and
     Level&nbsp;1 in terms of performance and redundancy. The hard disk
     space equals the number of disks used minus one. The data is
     distributed over the hard disks as with RAID&nbsp;0. <emphasis>Parity
     blocks</emphasis>, created on one of the partitions, are there for
     security reasons. They are linked to each other with XOR, enabling the
     contents to be reconstructed by the corresponding parity block in case
     of system failure. With RAID&nbsp;5, no more than one hard disk can
     fail at the same time. If one hard disk fails, it must be replaced as
     soon as possible to avoid the risk of losing data.
    </para>
   </sect2>

<!-- bg: this is not a common raid level. Merging to SLE_100
   <varlistentry>
    <term>RAID&nbsp;6</term>
    <listitem>
     <para>
      To further increase the reliability of the RAID system, it is
      possible to use RAID&nbsp;6. In this level, even if two disks 
      fail, the array still can be reconstructed. With
      RAID&nbsp;6, at least 4 hard disks are needed to run the array.
      Note, that when running as software raid, this
      configuration needs a considerable amount of CPU time and
      memory.
     </para>
    </listitem>
   </varlistentry> -->

   <sect2 id="bgchysf">
    <title>Nested RAID Levels</title>
    <para>
     Several other RAID levels have been developed, such as RAIDn,
     RAID&nbsp;10, RAID&nbsp;0+1, RAID&nbsp;30, and RAID&nbsp;50. Some of
     them being proprietary implementations created by hardware vendors.
     These levels are not very widespread, and are not explained here.
    </para>
   </sect2>
  </sect1>
  <sect1 id="sec.yast2.system.raid.yast">
   <title>Soft RAID Configuration with &yast;</title>

   <para>
    The &yast; soft RAID configuration can be reached from the &yast; Expert
    Partitioner. This partitioning tool enables you to edit and delete
    existing partitions and create new ones that should be used with soft
    RAID.
   </para>

   <para>
    You can create RAID partitions by first clicking <menuchoice>
    <guimenu>Create</guimenu><guimenu>Do not format</guimenu></menuchoice>
    then selecting <guimenu>0xFD Linux RAID</guimenu> as the partition
    identifier. For RAID&nbsp;0 and RAID&nbsp;1, at least two partitions are
    needed&mdash;for RAID&nbsp;1, usually exactly two and no more. If
    RAID&nbsp;5 is used, at least three partitions are required. It is
    recommended to use only partitions of the same size because each segment
    can contribute only the same amount of space as the smallest sized
    partition. The RAID partitions should be stored on different hard disks
    to decrease the risk of losing data if one is defective (RAID&nbsp;1 and
    5) and to optimize the performance of RAID&nbsp;0. After creating all
    the partitions to use with RAID, click
    <menuchoice><guimenu>RAID</guimenu><guimenu>Create
    RAID</guimenu></menuchoice> to start the RAID configuration.
   </para>

   <para>
    On the next page of the wizard, choose among RAID levels 0, 1, and 5,
    then click <guimenu>Next</guimenu>. The following dialog (see
    <xref linkend="fig.yast2.raid2" xrefstyle="FigureXRef"/>) lists all
    partitions with either the <guimenu>Linux RAID</guimenu> or
    <guimenu>Linux native</guimenu> type. No swap or DOS partitions are
    shown. If a partition is already assigned to a RAID volume, the name of
    the RAID device (for example, <filename>/dev/md0</filename>) is shown in
    the list. Unassigned partitions are indicated with <quote>--</quote>.
   </para>

   <figure pgwide="0" id="fig.yast2.raid2">
    <title>RAID Partitions</title>
<!--RAID partitions-->
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="yast2_raid2_a.png" width="329pt" format="PNG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="yast2_raid2_a.png" width="329pt" format="PNG"/>
     </imageobject>
    </mediaobject>
   </figure>

   <para>
    To add a previously unassigned partition to the selected RAID volume,
    first select the partition then click <guimenu>Add</guimenu>. At this
    point, the name of the RAID device is displayed next to the selected
    partition. Assign all partitions reserved for RAID. Otherwise, the space
    on the partition remains unused. After assigning all partitions, click
    <guimenu>Next</guimenu> to proceed to the settings dialog where you can
    fine-tune the performance (see
    <xref linkend="fig.yast2.raid3" xrefstyle="FigureXRef"/>).
   </para>

   <figure pgwide="0" id="fig.yast2.raid3">
    <title>File System Settings</title>
<!--File System Settings-->
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="yast2_raid3_a.png" width="329pt" format="PNG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="yast2_raid3_a.png" width="329pt" format="PNG"/>
     </imageobject>
    </mediaobject>
   </figure>

   <para>
    As with conventional partitioning, set the file system to use as well as
    encryption and the mount point for the RAID volume. After completing the
    configuration with <guimenu>Finish</guimenu>, see the
    <filename>/dev/md0</filename> device and others indicated with
    <emphasis>RAID</emphasis> in the Expert Partitioner.
   </para>
  </sect1>
  <sect1 id="bgchysg">
   <title>Troubleshooting Software RAIDs</title>

   <para>
    Check the <filename>/proc/mdstat</filename> file to find out whether a
    RAID partition has been damaged. In the event of a system failure, shut
    down your Linux system and replace the defective hard disk with a new
    one partitioned the same way. Then restart your system and enter the
    command <command>mdadm /dev/mdX --add /dev/sdX</command>. Replace
    <literal>X</literal> with your particular device identifiers. This
    integrates the hard disk automatically into the RAID system and fully
    reconstructs it.
   </para>

   <para>
    Although you can access all data during the rebuild, you might encounter
    some performance issues until the RAID has been fully rebuilt.
   </para>
  </sect1>
  <sect1 id="bgchysh">
   <title>For More Information</title>

   <para>
    Configuration instructions and more details for soft RAID can be found
    in the HOWTOs at:
   </para>

   <itemizedlist>
    <listitem>
     <para>
      <ulink url="https://raid.wiki.kernel.org/index.php/Linux_Raid"><citetitle>Linux
      RAID wiki</citetitle></ulink>
     </para>
    </listitem>
    <listitem>
     <para>
      <citetitle>The Software RAID HOWTO</citetitle> in the
      <filename>/usr/share/doc/packages/mdadm/Software-RAID.HOWTO.html</filename>
      file
     </para>
    </listitem>
   </itemizedlist>

   <para>
    Linux RAID mailing lists are also available, such as
    <ulink url="http://marc.info/?l=linux-raid"><citetitle/>linux-raid</ulink>.
   </para>
  </sect1>
 </chapter>
