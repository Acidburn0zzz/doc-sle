<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>

<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="cha.vm_guest">
 <title>Non-volatile memory</title>
 <info>
  <abstract>
   <para>
    This chapter contains additional information about using &productname; with
    non-volatile main memory comprising one or more NVDIMMs.
   </para>
  </abstract>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:bugtracker/>
   <dm:translation>yes</dm:translation>
  </dm:docmanager>
 </info>
 <sect1 xml:id="sec.nvdimm.intro">
  <title>Introduction to NVDIMMs</title>
  <para>
   NVDIMMs (non-volatile dual inline memory modules) are a new type of storage
   subsystem defined in version 6 of the ACPI standard.
  </para>
  <para>   
   Like SSDs, they provide non-volatile storage: their contents are retained
   when the system is powered off or restarted. However, they are installed
   directly into motherboard memory slots, like conventional Dynamic RAM (DRAM)
   DIMMs, and their contents are directly byte-addressable. (Disk-style sector-
   level access is also possible if that is more suitable.)
  </para>
  <para>
   Different models use different forms of electronic storage medium, such as
   Intel 3D XPoint, or a combination of NAND flash and DRAM, and in future,
   memristor storage or other forthcoming types of non-volatile memory.
  </para>
  <para>
   This means that different vendors' NVDIMMs offer different performance and
   durability characteristics. Typically, they are slower than DRAM, but
   considerably faster than solid-state disks based on NAND-flash technology.
  </para>
  <para>
   Because the storage technologies involved are in an early stage of
   development, different vendors' hardware may impose different limitations.
   However, generally, writing data to NVDIMMs is slower than reading from them,
   and the number of write cycles may be limited.
  </para>
  <para>   
   This has two important consequences.
  </para>
  <itemizedlist>
   <listitem>
    <para>
     It is not possible with current technology to run a system with only
     NVDIMMs and thus achieve non-volatile main memory. You must use a mixture
     of both conventional RAM and NVDIMMs. The operating system and
     applications will execute in conventional RAM, with the NVDIMMs providing
     very fast supplementary storage.
   </para>
   </listitem>
   <listitem>
    <para>
     The performance characteristics of different vendors' NVDIMMs mean that it
     may be necessary for programmers to be aware of the hardware specifications
     of NVDIMMS in a particular server, including how many and in which memory
     slots they are fitted. This will obviously impact hypervisor use, migration
     of software between different host machines, and so on.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1>
  <title>Terms</title>
  <variablelist>
   <varlistentry>
    <term>Region</term>
    <listitem>
     <para>
      A <literal>region</literal> is a block of persistent storage that can be divided up into
      one or more <literal>Namespaces</literal>. You cannot access the persistent memory of a
      Region without first allocating it to a Namespace.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Namespace</term>
    <listitem>
     <para>
      Each NVDIMM usually appears in the server's <filename>/dev</filename>
      directory as a block device. The storage must be assigned to one or more
      <literal>namespaces</literal> for it to be used. Depending on the method
      of access required, namespaces can either amalgamate storage from separate
      NVDIMMs into larger volumes, or allow it to be partitioned into smaller
      volumes, just like disk drives.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Mode</term>
    <listitem>
     <para>
      Each Namespace also has a <literal>Mode</literal> that defines which
      NVDIMM features are enabled for that Namespace. Namespace Modes include
      <literal>raw</literal>, <literal>sector</literal>, <literal>memory</literal> and <literal>DAX</literal>.
      Sibling Namespaces of the same parent Region will always have the same
      Type, but might be configured to have different Modes.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Type</term>
    <listitem>
     <para>
      Each Namespace and Region has a Type that defines the way in which the
      persistent memory associated with that Namespace or Region can be
      accessed. A Namespace always has the same Type as its parent Region. There
      are two different Types: <literal>PMEM</literal> and <literal>BLK</literal>.
     </para>
     <variablelist>
      <varlistentry>
       <term>PMEM</term>
       <listitem>
        <para>
         PMEM storage, like DRAM, offers byte-level access. This enables Direct
         Access (DAX), meaning that accessing the memory bypasses the kernel's
         page cache and goes direct to the medium. Additionally, using PMEM, a
         single namespace can include multiple interleaved NVDIMMs, allowing
         them all to be accessed as a single device.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>BLK</term>
       <listitem>
        <para>
         BLK access is in sectors, usually of 512 bytes, through a defined
         access window, the <literal>aperture</literal>. This behaviour is more
         like a traditional disk drive, and means that both reads and writes are
         cached by the kernel. With BLK/BTT access, each NVDIMM is accessed as a
         separate namespace.
        </para>
       </listitem>
      </varlistentry>
     </variablelist>
     <para>
      Some devices support both PMEM and BLK modes. Additionally, some allow the
      storage to be split into separate namespaces, so that some can be accessed
      using PMEM and some using BLK.
     </para>
     <para>      
      Either way, each namespace must be formatted with a filesystem, just as
      with a conventional drive. &productname; supports the <literal>ext2</literal>,
      <literal>ext4</literal> and <literal>XFS</literal> filesystems for this.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Direct Access (DAX)</term>
    <listitem>
     <para>
      Directly <literal>mmap()</literal> NV-RAM into a process' address space.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>DIMM Physical Address (DPA)</term>
    <listitem>
     <para>
      DIMM-relative offset - relative to the memory controller's interleave. For
      NVDIMMs which are not part of an interleaved set, the relationship between
      the physical address and the DPA is always 1:1.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Device-specific method (DSM)</term>
    <listitem>
     <para>
      ACPI method to access the firmware on an NVDIMM.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Label</term>
    <listitem>
     <para>
      Metadata on the NVDIMM for legacy (MBR or GPT) disk emulation.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
</chapter>
